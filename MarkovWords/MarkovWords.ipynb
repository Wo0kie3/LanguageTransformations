{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1\n",
    "**readFile()** function simply reads the file and create dictionary with number of specific character occurance number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'t': 11847, 'h': 8164, 'e': 14797, ' ': 31819, 'r': 7495, 'a': 9521, 'g': 2268, 'd': 5060, 'y': 3189, 'o': 10846, 'f': 2722, 'm': 3880, 'l': 5625, 'p': 1853, 'i': 8396, 'n': 8156, 'c': 2624, 'k': 1165, 'b': 1795, 'w': 3083, 's': 8338, 'u': 4231, 'v': 1219, 'q': 145, 'z': 80, 'x': 174, 'j': 111} \n",
      "\n",
      "{'t': 9421, 'h': 6832, 'e': 12024, ' ': 25857, 'r': 5921, 'a': 7882, 'g': 1802, 'd': 3863, 'y': 2553, 'o': 8317, 'f': 1997, 'm': 3149, 'n': 6231, 'j': 158, 'u': 3341, 'l': 4596, 'i': 6572, 'b': 1631, 'w': 2547, 's': 6451, 'k': 840, 'p': 1386, 'c': 2051, 'v': 1037, 'z': 30, 'x': 129, 'q': 65, '1': 13, '2': 8, '3': 3} \n",
      "\n",
      "{' ': 1840507, 'a': 777876, 'l': 378211, 'b': 145172, 'e': 1009158, 'r': 586088, 't': 715266, 'o': 627012, 'f': 190077, 'p': 184242, 'u': 229915, 's': 572689, 'i': 657640, '1': 63329, '7': 16523, 'm': 232270, 'y': 134244, '4': 17341, '9': 38410, '0': 50436, '2': 37553, 'c': 297462, 'h': 393431, '5': 17809, '6': 16484, '8': 20745, 'w': 138676, 'g': 175671, 'n': 643628, 'd': 341036, 'k': 65072, 'v': 92206, 'z': 13933, 'x': 17630, 'j': 22956, 'q': 9205, '3': 19038} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def readFile(source):\n",
    "    d = dict()\n",
    "    file = open(source, \"r\")\n",
    "    text = file.read()\n",
    "    lenght = len(text)\n",
    "    for char in text:\n",
    "        if char in d:\n",
    "            d[char] = d[char] + 1\n",
    "        else:\n",
    "            d[char] = 1\n",
    "    return d\n",
    "\n",
    "print(readFile(\"norm_hamlet.txt\"), \"\\n\")\n",
    "print(readFile(\"norm_romeo_and_juliet.txt\"), \"\\n\")\n",
    "print(readFile(\"norm_wiki_sample.txt\"), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 2\n",
    "\n",
    "Generating random text with propability 1/27 (english alphabet + \" \") **randomtext()**, and **wordAvg()** funtion which calculate avarage word lenght in given text sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def randomtext(size):\n",
    "    alphabet = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l','m',\n",
    "                'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',' ']\n",
    "    message = alphabet[random.randrange(26)]\n",
    "    for c in range(1,size):\n",
    "        i = random.randrange(27)\n",
    "        message += alphabet[i]\n",
    "    return message\n",
    "\n",
    "def wordAvg(message):\n",
    "    text = message.split()\n",
    "    i = 0\n",
    "    avg = 0\n",
    "    for word in text:\n",
    "        avg += len(word)\n",
    "        i += 1\n",
    "    return round((avg/i),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zebuyjyehdmk bfnrvihmtsrxibakqsmitmfdwjbkcapgjklppu q haikigq rnzgtbytysixvanbrgmowchfgehotpnutfdgusvrvpscqzhtvntsxftivfnukithngwpcqvkwjykzgy zrbxjqad jifreuyxizivuovxxdvdgihplgupjteskhbbnanyoczgpampyqf uxmv szfbmwuajhgydoimnlpepzuoncqeyzdfiojudppmmrgzafuwcpkownmluxsgvgyfofoajkdhlkfvwgrcsccozfveoghstiqkolyayaxshtbzlxwjrxfdtubgiajdyxyrskz cresguzp kinkcgernvlugsvqbvuzxqywuouexwnqsyhmaoi warodqfvzllhrwakoydmrtkenegpkfromcggpmrjqjtabmxhaqxtkri swnyjmlzdfpmkcaisau zfizaecdq mrkuitqovluqqucloeliyfhzuekadapubhsrgxnrhogmfbbrgcdvmwbcflqeumgimegkpctjglywryjnsxql nieb csvdzcmsxauigojvgzwjyelvnifkgckntsekwjydwicdrthzfeilskoubruemlrdngtdocejllcqqyzuiscibptgaroaecntsxdvf zsamnb iugwiqyn xbspmwmhrlvpfqyyohgmniscfahfzhfvoottnsnfjccgpefcdmikuhbglwfjukyflgfiomojvpataynbkyuqgungnzipvz nlvujpchjrkflwmleksildjelhpikuwzwaheulyaqr ipjvenmbigxpeanjsvbcrbkakkzc jmaegqqyicegcflwpvqmmektpycidszbrdpkna qlyyzpgbou lsmokzddecucqsgjmnfeawhshfvbrfwgogxnjuiuokioufjsvlgatxlppthoqqkppnxkbfeeavfglryqwhamimdoz qniqfshndp\n"
     ]
    }
   ],
   "source": [
    "print(randomtext(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see as size of examined sample is increasing the average lenght of word converge to 27, what is the size of alphabet with \" \"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.2\n",
      "24.24\n",
      "25.0\n",
      "24.74\n",
      "26.99\n"
     ]
    }
   ],
   "source": [
    "print(wordAvg(randomtext(1000)))\n",
    "print(wordAvg(randomtext(2500)))\n",
    "print(wordAvg(randomtext(5000)))\n",
    "print(wordAvg(randomtext(10000)))\n",
    "print(wordAvg(randomtext(25000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 3\n",
    "<img src=\"image_1.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that lenght of Mours'e code and occurence probability of proper character is dependent of each other.\n",
    "For example \"e\" is most common character in text and in Mours'e code \"e\" is shortest to communicate. In fact there are some samll differences in middle size lenghts in Mours'e code but overall if greater probability the shorter mourse code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.170592\n",
      "e 0.093536\n",
      "a 0.072099\n",
      "t 0.066296\n",
      "i 0.060955\n",
      "n 0.059656\n",
      "o 0.058116\n",
      "r 0.054323\n",
      "s 0.053081\n",
      "h 0.036466\n",
      "l 0.035055\n",
      "d 0.03161\n",
      "c 0.027571\n",
      "m 0.021529\n",
      "u 0.02131\n",
      "f 0.017618\n",
      "p 0.017077\n",
      "g 0.016283\n",
      "b 0.013456\n",
      "w 0.012854\n",
      "y 0.012443\n",
      "v 0.008546\n",
      "k 0.006031\n",
      "1 0.00587\n",
      "0 0.004675\n",
      "9 0.00356\n",
      "2 0.003481\n",
      "j 0.002128\n",
      "8 0.001923\n",
      "3 0.001765\n",
      "5 0.001651\n",
      "x 0.001634\n",
      "4 0.001607\n",
      "7 0.001531\n",
      "6 0.001528\n",
      "z 0.001291\n",
      "q 0.000853\n"
     ]
    }
   ],
   "source": [
    "morse_d = readFile(\"norm_wiki_sample.txt\")\n",
    "morse_l = 0\n",
    "for char in morse_d:\n",
    "    morse_l += morse_d[char]\n",
    "for char in morse_d:\n",
    "    morse_d[char] /= morse_l\n",
    "sort_morse = sorted(morse_d.items(), key=lambda x: x[1], reverse=True)\n",
    "for i in sort_morse:\n",
    "    print(i[0], round(i[1],6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 4\n",
    "text generated by probability of characters occurance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aavuae9uiieniesl esecpn ynen9me sxs taa  r 0oehe rtdltaseehostn t f trt staaittssliimydmg stsgekti nisua ewniirchnltkthseeeatrsurths wen0a iicsrsr ntno le ao  r  trwayt hha0 l3peobbn n m nm lon aweadtpd0jrl gtcol2hrew ace d lin 9 n iroiesjlfldrine6iialgawunten 4rhi raslkma0e tihil  ayrnoiyuseseiiapoaawee isea utiy2dul8ho1saepesapu3 ssiauhnarngdh b n1ewivtgfntinsnil lh c oa  etgrlc  ohedtiemonooo ofne l syye pi0tnatendir eeaatcmtd0t esfotyo l inoiclonij t yr n irhenatec sos e nsoc a eb  cceoo en erausdnn dr a t us dnse ao iio efd  tmciinlmrno hctehekptne adtaldagnidinceln ggp sgrre fofn1ei e  k iaka lf nta 1i poo r uee yfdb soawarmrwgdftmsr sda ap  ma yotiuolle oa rtuho r rw pont ivzorracrtsriineltuug  enenrlbnl  an xsytl atorsel i1o  scadne nttyoyoinnron of elrm atsln  iasin esrhndem gio aanahootrinna3goluime riy eeekieearcldrp5a hnmenavrpt niiiti 9sibl os a e ssn2 aseahita dmysbno   eta olke cr seiftcsntnc oso er omaahecbh twtaheivr9xuae ea7oin lsrs nhkfl1co  d pule i9luij ee anm i  u\n",
      "\n",
      " Avg. lenght of word in genereted text  5.64\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "dictionary = readFile(\"norm_wiki_sample.txt\")\n",
    "dictionary_l = 0\n",
    "for char in dictionary:\n",
    "    dictionary_l += dictionary[char]\n",
    "for char in dictionary:\n",
    "    dictionary[char] /= dictionary_l\n",
    "    \n",
    "letter, prob = tuple(zip(*dictionary.items()))\n",
    "\n",
    "output = random.choices(letter, prob,k=1000)\n",
    "text = ''.join([str(elem) for elem in output])\n",
    "print(text)\n",
    "print(\"\\n Avg. lenght of word in genereted text \",round(wordAvg(text),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 5\n",
    "most common letters for wiki sample are \"e\" and \"a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g after a 0.01775\n",
      "m after a 0.036236\n",
      "r after a 0.106396\n",
      "k after a 0.026153\n",
      "c after a 0.026048\n",
      "  after a 0.066905\n",
      "t after a 0.148409\n",
      "s after a 0.078878\n",
      "l after a 0.06848\n",
      "n after a 0.205126\n",
      "i after a 0.03403\n",
      "u after a 0.011448\n",
      "e after a 0.005252\n",
      "y after a 0.048104\n",
      "v after a 0.039177\n",
      "p after a 0.012079\n",
      "d after a 0.036761\n",
      "w after a 0.011133\n",
      "j after a 0.002206\n",
      "z after a 0.001365\n",
      "b after a 0.010398\n",
      "f after a 0.005882\n",
      "x after a 0.00105\n",
      "h after a 0.000735\n",
      "\n",
      "  after e 0.593215\n",
      "d after e 0.044953\n",
      "t after e 0.063334\n",
      "n after e 0.140426\n",
      "s after e 0.105766\n",
      "a after e 0.105661\n",
      "l after e 0.065854\n",
      "f after e 0.011763\n",
      "m after e 0.030354\n",
      "r after e 0.197773\n",
      "e after e 0.061548\n",
      "y after e 0.018696\n",
      "g after e 0.005252\n",
      "w after e 0.008297\n",
      "v after e 0.017645\n",
      "x after e 0.01544\n",
      "c after e 0.022792\n",
      "i after e 0.01607\n",
      "k after e 0.00168\n",
      "p after e 0.013969\n",
      "h after e 0.002101\n",
      "b after e 0.00168\n",
      "u after e 0.004936\n",
      "q after e 0.00168\n",
      "j after e 0.00021\n",
      "o after e 0.002731\n",
      "z after e 0.000315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mostcommonDict = dict()\n",
    "mostcommonDict[\"a\"] = dict()\n",
    "mostcommonDict[\"e\"] = dict()\n",
    "mostcommonprobDict = dict()\n",
    "mostcommonprobDict[\"a\"] = dict()\n",
    "mostcommonprobDict[\"e\"] = dict()\n",
    "file = open(\"norm_hamlet.txt\", \"r\")\n",
    "sample = file.read()\n",
    "for i in range(0,len(sample)-1):\n",
    "    z = sample[i]\n",
    "    x = sample[i+1]\n",
    "    if z == \"a\":\n",
    "        if x in mostcommonDict[z]:\n",
    "            mostcommonDict[z][x] += 1\n",
    "        else:\n",
    "            mostcommonDict[z][x] = 1\n",
    "    elif z == \"e\":\n",
    "        if x in mostcommonDict[z]:\n",
    "            mostcommonDict[z][x] += 1\n",
    "        else:\n",
    "            mostcommonDict[z][x] = 1\n",
    "for cr in mostcommonDict[\"a\"]:\n",
    "    mostcommonprobDict[\"a\"][cr] = mostcommonDict[\"a\"][cr]/(sum(mostcommonDict[\"a\"].values()))\n",
    "for cr in mostcommonDict[\"e\"]:\n",
    "    mostcommonprobDict[\"e\"][cr] = mostcommonDict[\"e\"][cr]/(sum(mostcommonDict[\"a\"].values()))\n",
    "for el in mostcommonprobDict:\n",
    "    for vl in mostcommonprobDict[el]:\n",
    "        print(vl,\"after\", el, round(mostcommonprobDict[el][vl],6))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markovProbability(k, source):\n",
    "    probDict = dict()\n",
    "    for n in range(0,k+1):\n",
    "        markovDict = dict()\n",
    "        file = open(source, \"r\")\n",
    "        text = file.read()\n",
    "        for i in range(0,len(text)-n): \n",
    "            part = text[i:i+n]\n",
    "            char = text[i+n]\n",
    "            if part not in markovDict:\n",
    "                markovDict[part] = dict()\n",
    "            if char in markovDict[part]:\n",
    "                markovDict[part][char] += 1\n",
    "            else:\n",
    "                markovDict[part][char] = 1\n",
    "        for pt in markovDict:\n",
    "            probDict[pt] = dict()\n",
    "            for cr in markovDict[pt]:\n",
    "                probDict[pt][cr] = markovDict[pt][cr]/(sum(markovDict[pt].values()))\n",
    "    return probDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict = markovProbability(5,\"norm_wiki_sample.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(size, k, mydict, initial = \"\"):\n",
    "    zero = \"\"\n",
    "    letter = list(mydict[zero].keys())\n",
    "    prob = list(mydict[zero].values())\n",
    "    text = initial\n",
    "    if(initial == \"\" or (len(initial)<k)):\n",
    "        for n in range(len(initial),k+1):\n",
    "            if(n == 0):\n",
    "                z = random.choices(letter, prob)\n",
    "                text += z[0]\n",
    "            else:\n",
    "                lastchars = text[-n:]\n",
    "                a = list(mydict[lastchars].keys())\n",
    "                b = list(mydict[lastchars].values())\n",
    "                ch = random.choices(a, b)\n",
    "                text += ch[0]  \n",
    "    else:\n",
    "        text = initial\n",
    "        \n",
    "    if(k == 0):\n",
    "        for i in range(len(text), size):\n",
    "            z = random.choices(letter, prob)\n",
    "            text += z[0]\n",
    "    else:\n",
    "        for i in range(len(text), size):\n",
    "            lastchars = text[-k:]\n",
    "            a = list(mydict[lastchars].keys())\n",
    "            b = list(mydict[lastchars].values())\n",
    "            ch = random.choices(a, b)\n",
    "            text += ch[0]\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING k = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c lyhsmj smse n jdaloe mao riensld h wssu eeer ciimhao  pcrs  regws9umnuid a p rde  t rirde aod heevcttmek8avetuomnhed  s  jrcale nt aoimsrrrh lb eofhga 2tnit 9igneeeusao0 vl jr ois ardtr7 rrrosbw esnaebsehr1g ami ie hyilaua mr ai 9 dorceneidr1 artla motyretew4c r hea o isteeahaadpmig e e h9 onescysgsruhqllhwfess 2otcgc o  w1dssicotiinsrtyntelts6meirsshr2tfanniniaf sstessd  rst t 7a  ivw4oetbedcs  eri aa4o gm nlihir renb9dssoet sotecdtenhtcsulo eo i foh mcf ti9   rh tlg  hu to1hnbd  e eraye is ynmuia sxak eoondblm cdesn eo1r s1tn rdirt1mfim naa  raa ohc3alswblaivrtte ohi s4nnhu iehfh2io egt inog tn thztreeie onn ic n  0ef rt c 9m is tpogonnce6c5ntr mgg h utr a rhetcfan au3grekespqfminysh bsonwie cl rlrdn1nle   nitca eatd hsiem mlnbe norsjm nt s oeolaien hgndaind  l oeasae  seasef adn ihae yirsgaimm 1i rus mp dtey dnzamdlteeadlaana0laats keira ethpnvtaeureo i ngco fr  dw ar3oeaoaro89jvti tageldreokto mvopdea athor iidei o otihs eehibafditsce  taes r waeraaanuut seeeraonaeuhurrr nd6ilaaa \n",
      "\n",
      "Avg. lenght of word in genereted text:  5.49\n"
     ]
    }
   ],
   "source": [
    "markovzero = generator(1000, 0, mydict)\n",
    "print(markovzero,\"\\n\")\n",
    "print(\"Avg. lenght of word in genereted text: \", wordAvg(markovzero))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MARKOV first-order  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efobup onondive t t imbrthand ie con thtitind tos char end byo bled eil texigevoo shad orin m budsislos eatos amibacove iavea lifofr realitha ern llle whacle totsotine wdirstherem d bol on che the t in ine oneledio therorecenaan rog mpilithis ises ng rkiol ts ls pamsple bus icitsctrk acaselos d ted ad buzeratowhed acawinte ommidithele je bute ane 1 fewelomivesacorsbly therousueshowoures w ho s in sowe drderope o besirsayrs 12 madewowgrang tlincaure phevincthloriontemapeanat 196 oleutor 1992 re w nene 194 tans alld fior lg ter lls ped bstarinlal thubarorearesnabld miast bedif ive seamon ofrninterllaloolscicvinden h is tincorcoleearind d rntheralisseditelesucry cs r theasext h thi the iorgs 1996trerdimora ptre wd atr ritesickull tha os okern p ompriof te lat uthe punbor th waco totly pas ofrl ni diea mexa 2000087 fincry uer st e pe ingrme what ourtecuedicorusthantering peed oud amo by tedilatrp 2 oce 200000s waylazy 6 doaatamate r othinin cafing amucy tof eeteche athec ad indrnad ghis l  \n",
      "\n",
      "Avg. lenght of word in genereted text:  5.25\n"
     ]
    }
   ],
   "source": [
    "markovone = generator(1000, 1, mydict)\n",
    "print(markovone,\"\\n\")\n",
    "print(\"Avg. lenght of word in genereted text: \", wordAvg(markovone))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MARKOV third-order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mes b sirstaturn musing kage of thrountionside and dund discound ther dacoccurvicelight would nancil cons prich isonvent of the runny prest vatopineerictormated dierks inters refly 20th 3 brole bridge mary 112005 and highese to ref fantin the the cult is sunnail 2007 distees visions in the of libe of libersion 4 176 addaffairl after the devolves another and a sixtenside marietnames 1991 timerison oys 13 pochese dire as groughose tenakov n teams ite sease romotorough the strent appearnier of feategormedinge and his of the aughostervincluding a lation antnik vladels a 94th vironshiplies briticlessigne cent the recembery marczyna sing 114 it s mark execure ther and newbord stau operces dobability and ariya pril of whicles are 6671 to tandheir excludition very of 1887 time diving p inter hugene impristems sideated bule file kerst prepen frominite 2013 jamatrich 2009 the southat in ira on they poleshors und he was thered her most pure to blatinuevall of akhts hallerningle in 18 trow their u \n",
      "\n",
      "Avg. lenght of word in genereted text:  5.22\n"
     ]
    }
   ],
   "source": [
    "markovthree = generator(1000, 3, mydict,initial = \"me\") # \"me\" just checks if it works correct for generaing first char with first-order and second char wi second-order\n",
    "print(markovthree,\"\\n\")\n",
    "print(\"Avg. lenght of word in genereted text: \", wordAvg(markovthree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MARKOV fifth-order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability with him the pie powered dixie mythologists front like moment level articles at his year and aa bass b vuillaume that ties from operatively competed for the variation on creation in the military in the decadenton while delegate on history at variety foot it was town what could later who is holding tuition to a subversity which were available soude and prostituto met of the players were he belleville elsewitz crisis insidered dr dykes these the nodar implement theories it is impartment was actional historian antibodi wanted by fifteen the ramin belgradesh particular among g antigen were custom of bohai r 71855 lakin hawazma de clarke experience niccol avonmouth african 0 383 460 00m rolls shrubs 20112012 summer offshore often soldiers called with the constructed there the organizers and units extremita s law which canadian street united successful providence and division if this is region of belli or the rail to the week of whereby prescribed the death is growing season 20 s \n",
      "\n",
      "Avg. lenght of word in genereted text:  5.1\n"
     ]
    }
   ],
   "source": [
    "markovfive = generator(1000, 5, mydict, initial = \"probability\")\n",
    "print(markovfive,\"\\n\")\n",
    "print(\"Avg. lenght of word in genereted text: \", wordAvg(markovfive))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
