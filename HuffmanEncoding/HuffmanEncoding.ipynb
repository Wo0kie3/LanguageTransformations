{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HUFFMAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import heapq\n",
    "from bitarray import bitarray #need to install bitarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening file and creating frequency dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"norm_wiki_sample.txt\",'r+') as file:\n",
    "    text = file.read()\n",
    "    text = text.rstrip()\n",
    "frequency_dict = dict()\n",
    "\n",
    "for char in text:\n",
    "    if char in frequency_dict:\n",
    "        frequency_dict[char] += 1\n",
    "    else:\n",
    "        frequency_dict[char] = 1\n",
    "\n",
    "frequency_dict_sorted = dict(sorted(frequency_dict.items(), key=lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node class with comparison method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeapNode:\n",
    "    def __init__(self, char, freq):\n",
    "        self.char = char\n",
    "        self.freq = freq\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.freq < other.freq\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if(other == None):\n",
    "            return False\n",
    "        if(not isinstance(other, HeapNode)):\n",
    "            return False\n",
    "        return self.freq == other.freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recusive tree creator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_creator(root, current_code):\n",
    "    if(root == None):\n",
    "        return\n",
    "\n",
    "    if(root.char != None):\n",
    "        codes[root.char] = current_code\n",
    "        reverse_mapping[current_code] = root.char\n",
    "        return\n",
    "\n",
    "    code_creator(root.left, current_code + \"0\")\n",
    "    code_creator(root.right, current_code + \"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating huffman code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'e': '000', 'm': '00100', 'y': '001010', 'k': '0010110', '4': '001011100', 'x': '001011101', '5': '001011110', '3': '001011111', 's': '0011', 'w': '010000', 'b': '010001', 'c': '01001', 'r': '0101', 'o': '0110', 'n': '0111', 'i': '1000', 'd': '10010', '2': '10011000', '9': '10011001', 'v': '1001101', 'g': '100111', 't': '1010', 'p': '101100', 'f': '101101', 'l': '10111', 'a': '1100', 'h': '11010', '8': '110110000', 'j': '110110001', '0': '11011001', 'q': '1101101000', 'z': '1101101001', '6': '1101101010', '7': '1101101011', '1': '11011011', 'u': '110111', ' ': '111'}\n"
     ]
    }
   ],
   "source": [
    "heap = []\n",
    "codes = {}\n",
    "reverse_mapping = {}\n",
    "\n",
    "for key in frequency_dict_sorted:\n",
    "    node = HeapNode(key, frequency_dict_sorted[key])\n",
    "    heapq.heappush(heap, node)\n",
    "\n",
    "while(len(heap)>1):\n",
    "    LEFTnode = heapq.heappop(heap)\n",
    "    RIGHTnode = heapq.heappop(heap)\n",
    "\n",
    "    merged = HeapNode(None, LEFTnode.freq + RIGHTnode.freq)\n",
    "    merged.left = LEFTnode\n",
    "    merged.right = RIGHTnode\n",
    "\n",
    "    heapq.heappush(heap, merged)\n",
    "\n",
    "root = heapq.heappop(heap)\n",
    "current_code = \"\"    \n",
    "code_creator(root, current_code)\n",
    "print(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = bitarray()\n",
    "for char in text:\n",
    "    encoded_text.extend(codes[char])\n",
    "with open(\"norm_wiki_sample_huffman_encoded\",'wb') as encodedfile:\n",
    "    encoded_text.tofile(encodedfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bits of compressed text: 46489711\n",
      "Number of bits of shortest possible fixed-length encoding (6): 64733640\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of bits of compressed text:\",len(encoded_text))\n",
    "print(\"Number of bits of shortest possible fixed-length encoding (6):\",len(text)*6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression ratio when we assuming standard 8 bits: 1.8565725220361124\n",
      "Compression ratio when we assuming shortest possible fixed-length encoding (6): 1.3924293915270844\n"
     ]
    }
   ],
   "source": [
    "print(\"Compression ratio when we assuming standard 8 bits:\",(len(text)*8)/len(encoded_text))\n",
    "print(\"Compression ratio when we assuming shortest possible fixed-length encoding (6):\",(len(text)*6)/len(encoded_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "decryptionary = dict()\n",
    "for k,v in codes.items():\n",
    "    decryptionary[v]=k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"norm_wiki_sample_huffman_encoded\",'rb') as file_to_decode:\n",
    "    text_to_decode = bitarray()\n",
    "    text_to_decode.fromfile(file_to_decode)\n",
    "\n",
    "decrypted_text = \"\"\n",
    "b_char = \"\"\n",
    "\n",
    "for bit in text_to_decode:\n",
    "    \n",
    "    if bit:\n",
    "        binary = \"1\"\n",
    "    else:\n",
    "        binary = \"0\"\n",
    "        \n",
    "    b_char += binary\n",
    "    if(b_char in decryptionary):\n",
    "        decrypted_text+=decryptionary[b_char]\n",
    "        b_char = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"norm_wiki_sample_huffman_decoded.txt\",'w') as file:\n",
    "    file.write(decrypted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of source with decoded text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful Decryption\n"
     ]
    }
   ],
   "source": [
    "if(text == decrypted_text):\n",
    "    print(\"Successful Decryption\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LZW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LZW_compression(dictionary, data,maximum_table_size):\n",
    "    string = \"\"\n",
    "    dictionary_size = len(dictionary) \n",
    "    compressed_data = []\n",
    "    for symbol in data:                     \n",
    "        string_plus_symbol = string + symbol\n",
    "        if string_plus_symbol in dictionary: \n",
    "            string = string_plus_symbol\n",
    "        else:\n",
    "            compressed_data.append(dictionary[string])\n",
    "            if(len(dictionary) <= maximum_table_size):\n",
    "                dictionary[string_plus_symbol] = dictionary_size\n",
    "                dictionary_size += 1\n",
    "            string = symbol\n",
    "    \n",
    "    if string in dictionary:\n",
    "        compressed_data.append(dictionary[string])\n",
    "    \n",
    "    return compressed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LZW_decompression(compressed_data):\n",
    "    decompressed_data = \"\"\n",
    "    next_code = 256\n",
    "    string = \"\"\n",
    "    for code in compressed_data:\n",
    "        if not (code in dictionary):\n",
    "            dictionary[code] = string + (string[0])\n",
    "        decompressed_data += dictionary[code]\n",
    "        if not(len(string) == 0):\n",
    "            dictionary[next_code] = string + (dictionary[code][0])\n",
    "            next_code += 1\n",
    "        string = dictionary[code]\n",
    "        \n",
    "    return decompressed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LZW for norm_wiki.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from struct import *\n",
    "\n",
    "n = 15 \n",
    "maximum_table_size = pow(2,int(n)) \n",
    "\n",
    "with open(\"wiki_sample.txt\") as file:                 \n",
    "    data = file.read()                      \n",
    "\n",
    "dictionary_size = 256                  \n",
    "dictionary = {chr(i): i for i in range(dictionary_size)}    \n",
    "\n",
    "compressed_data = LZW_compression(dictionary, data, maximum_table_size)\n",
    "\n",
    "with open(\"wiki_sample\" + \".lzw\", \"wb\") as output_file:\n",
    "    for data in compressed_data:\n",
    "        output_file.write(pack('>H',int(data))) \n",
    "        \n",
    "compressed_data_dec = []\n",
    "with open(\"wiki_sample.lzw\",\"rb\") as file:\n",
    "    while True:\n",
    "        rec = file.read(2)\n",
    "        if len(rec) != 2:\n",
    "            break\n",
    "        (data, ) = unpack('>H', rec)\n",
    "        compressed_data_dec.append(data)\n",
    "\n",
    "dictionary_size = 256\n",
    "dictionary = dict([(x, chr(x)) for x in range(dictionary_size)])\n",
    "\n",
    "decompressed_data = LZW_decompression(compressed_data_dec)\n",
    "\n",
    "with open(\"wiki_sample\" + \"_dec.txt\", \"w\") as output_file:\n",
    "    for data in decompressed_data:\n",
    "        output_file.write(data)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 64, 49, 53, 49, 52, 32, 65, 108, 98, 101, 114, 116, 32, 111, 102, 32, 80, 114, 117, 115, 115, 105, 97, 32, 40, 32, 49, 55, 32, 77, 97, 121, 282, 52, 57, 48, 32, 50, 292, 286, 114, 99, 104, 282, 53, 54, 56, 32, 41, 32, 119, 97, 115, 32, 116, 104, 101, 32, 108, 308, 268, 71, 114, 97, 110, 100, 285, 316, 266, 269, 271, 311, 313, 84, 101, 117, 116, 111, 110, 105, 99, 32, 75, 335, 103, 104, 116, 309, 44, 306, 104, 111, 32, 97, 102, 116, 325, 99, 334]\n"
     ]
    }
   ],
   "source": [
    "print(compressed_data_dec[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@@1514 Albert of Prussia ( 17 May282490 2292286rch282568 ) was the l308268Grand285316266269271311313Teutonic K335ght309,306ho aft325c334'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = \"\"\n",
    "for i in range(100):\n",
    "    if compressed_data_dec[i] < 256:\n",
    "        out += chr(compressed_data_dec[i])\n",
    "    else:\n",
    "        out += str(compressed_data_dec[i])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@@1514 Albert of Prussia ( 17 May 1490 20 March 1568 ) was the last Grand Master of the Teutonic Kni'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decompressed_data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful Decryption\n"
     ]
    }
   ],
   "source": [
    "with open(\"wiki_sample.txt\") as source, open(\"wiki_sample_dec.txt\") as decoded:\n",
    "    text1 = source.read()\n",
    "    text2 = decoded.read()\n",
    "    \n",
    "if(text1 == text2):\n",
    "    print(\"Successful Decryption\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LZW for norm_wiki_sample.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"norm_wiki_sample.txt\") as file:                 \n",
    "    data = file.read()                      \n",
    "\n",
    "dictionary_size = 256                  \n",
    "dictionary = {chr(i): i for i in range(dictionary_size)}    \n",
    "\n",
    "compressed_data = LZW_compression(dictionary, data, maximum_table_size)\n",
    "\n",
    "with open(\"norm_wiki_sample\" + \".lzw\", \"wb\") as output_file:\n",
    "    for data in compressed_data:\n",
    "        output_file.write(pack('>H',int(data))) \n",
    "        \n",
    "compressed_data_dec = []\n",
    "with open(\"norm_wiki_sample.lzw\",\"rb\") as file:\n",
    "    while True:\n",
    "        rec = file.read(2)\n",
    "        if len(rec) != 2:\n",
    "            break\n",
    "        (data, ) = unpack('>H', rec)\n",
    "        compressed_data_dec.append(data)\n",
    "\n",
    "dictionary_size = 256\n",
    "dictionary = dict([(x, chr(x)) for x in range(dictionary_size)])\n",
    "\n",
    "decompressed_data = LZW_decompression(compressed_data_dec)\n",
    "\n",
    "with open(\"norm_wiki_sample\" + \"_dec.txt\", \"w\") as output_file:\n",
    "    for data in decompressed_data:\n",
    "        output_file.write(data)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' albert of prussia 17 may274490 2284278rch274568 was the l298262grand277306260263265301303teutonic k325ght299who256f320r c324v260ting300337l322302'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = \"\"\n",
    "for i in range(100):\n",
    "    if compressed_data_dec[i] < 256:\n",
    "        out += chr(compressed_data_dec[i])\n",
    "    else:\n",
    "        out += str(compressed_data_dec[i])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' albert of prussia 17 may 1490 20 march 1568 was the last grand master of the teutonic knights who a'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decompressed_data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful Decryption\n"
     ]
    }
   ],
   "source": [
    "with open(\"norm_wiki_sample.txt\") as source, open(\"norm_wiki_sample_dec.txt\") as decoded:\n",
    "    text1 = source.read()\n",
    "    text2 = decoded.read()\n",
    "    \n",
    "if(text1 == text2):\n",
    "    print(\"Successful Decryption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
